<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>pyfocusr.focusr API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>pyfocusr.focusr</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import numpy as np
from scipy.spatial import KDTree
from scipy.optimize import linear_sum_assignment
from scipy.spatial.distance import cdist
from .graph import Graph
import cycpd
from itkwidgets import Viewer
from matplotlib import colors
from .vtk_functions import *
from .main import *
from .eigsort import eigsort
import time


class Focusr(object):
    def __init__(self,
                 vtk_mesh_target,
                 vtk_mesh_source,
                 icp_register_first=True,               # bool, should register meshes together first
                 icp_registration_mode=&#39;rigid&#39;,         # str - should icp reg be rigid or similarity (rigid + scale)
                 icp_reg_target_to_source=False,        # bool of what should be registered to what in ICP.
                 n_spectral_features=3,                 #
                 n_extra_spectral=3,                    #
                 target_eigenmap_as_reference=True,     # bool, should use target eigenmap as reference for spectral reg
                                                        # This is helpful for registering a &#34;template&#34; mesh (which is the source)
                                                        # to another mesh (which is the target), commonly performed in
                                                        # statistical shape models (SSM).
                 norm_physical_and_spectral=True,       #
                 n_coords_spectral_ordering=5000,       #
                 n_coords_spectral_registration=5000,   #
                 rigid_before_non_rigid_reg=True,       #
                 rigid_reg_max_iterations=100,          #
                 rigid_tolerance=1e-8,                  #
                 non_rigid_max_iterations=1000,         #
                 non_rigid_tolerance=1e-8,              #
                 non_rigid_alpha=0.5,                   #
                 non_rigid_beta=3.0,                    #
                 non_rigid_n_eigens=100,                #
                 include_points_as_features=False,      #
                 get_weighted_spectral_coords=True,     #
                 graph_smoothing_iterations=300,        #
                 feature_smoothing_iterations=40,       #
                 smooth_correspondences=True,           #
                 return_average_final_points=True,      # should we create diffused/weighted new points
                 return_nearest_final_points=True,      # should we create nearest neighbor new points.
                 return_transformed_mesh=True,          #
                 projection_smooth_iterations=40,       #
                 feature_weights=None,                  #
                 initial_correspondence_type=&#39;kd&#39;,      # &#39;kd&#39; or &#39;hungarian&#39;
                 final_correspondence_type=&#39;kd&#39;,        #
                 list_features_to_calc=[&#39;curvature&#39;],   # include as input of graph_source &amp; graph_target
                 list_features_to_get_from_mesh=[],     # &#39;thickness (mm)&#39; - get info from mesh surface for reg
                 use_features_as_coords=False,          #
                 use_features_in_graph=False,           #
                 include_features_in_adj_matrix=False,  # include as input of graph_source &amp; graph_target
                 G_matrix_p_function=&#39;exp&#39;,             # Param for feature processing before laplacian creation
                 norm_node_features_std=True,           # Param for feature processing before laplacian creation
                 norm_node_features_cap_std=3,          # Param for feature processing before laplacian creation
                 norm_node_features_0_1=True,           # Param for feature processing before laplacian creation
                 verbose=False                          # bool - setting whether should print extraneous details
                 ):
        self.verbose = verbose
        print(&#39;Starting Focusr&#39;)
        # Inputs
        #   Spectral coordinates based inputs/parameters
        self.n_spectral_features = n_spectral_features
        self.n_extra_spectral = n_extra_spectral
        self.n_total_spectral_features = self.n_spectral_features + self.n_extra_spectral
        self.target_eigenmap_as_reference = target_eigenmap_as_reference

        #   Normalization &amp; what included in registration
        self.norm_physical_and_spectral = norm_physical_and_spectral  # Bool, norm spect&amp;xyz. Otherwise, spect to xyz.
        self.include_points_as_features = include_points_as_features  # include xyz coords in registration
        self.get_weighted_spectral_coords = get_weighted_spectral_coords
        self.feature_smoothing_iterations = feature_smoothing_iterations  # number smooth iterations to extra features
        #   Registration parameters (general)
        self.n_coords_spectral_registration = n_coords_spectral_registration  # max n points for registration
        #       Rigid reg params
        self.rigid_before_non_rigid_reg = rigid_before_non_rigid_reg
        self.rigid_reg_max_iterations = rigid_reg_max_iterations
        self.rigid_tolerance = rigid_tolerance
        #       Deformable reg params
        self.non_rigid_max_iterations = non_rigid_max_iterations
        self.non_rigid_tolerance = non_rigid_tolerance
        self.non_rigid_alpha = non_rigid_alpha
        self.non_rigid_beta = non_rigid_beta
        self.non_rigid_n_eigens = non_rigid_n_eigens
        #   Correspondence selection parameters
        self.initial_correspondence_type = initial_correspondence_type
        self.smooth_correspondences = smooth_correspondences  # Bool - smooth values to improve diffeomorphism?
        self.return_average_final_points = return_average_final_points  # make weighted avg final xyz position?
        self.return_nearest_final_points = return_nearest_final_points  # make nearest neighbour final xyz position?
        self.graph_smoothing_iterations = graph_smoothing_iterations
        self.projection_smooth_iterations = projection_smooth_iterations  # n iterations projection smoothing
        self.final_correspondence_type = final_correspondence_type  # &#39;kd&#39; or &#39;hungarian&#39; correspondence
        self.return_transformed_mesh = return_transformed_mesh  # bool to tell if we should create new mesh.

        print(&#39;Starting ICP&#39;)
        # Prepare Meshes / Graphs
        #   Rigidly register target to source before beginning.
        #   This ensures they are in same space for all steps.
        if icp_register_first is True:
            if icp_reg_target_to_source is True:
                if icp_registration_mode == &#39;rigid&#39;:
                    icp = icp_transform(target=vtk_mesh_source, source=vtk_mesh_target, transform_mode=&#39;rigid&#39;)
                elif icp_registration_mode == &#39;similarity&#39;:
                    icp = icp_transform(target=vtk_mesh_source, source=vtk_mesh_target, transform_mode=&#39;similarity&#39;)
                vtk_mesh_target = apply_transform(source=vtk_mesh_target, transform=icp)
            elif icp_reg_target_to_source is False:
                if icp_registration_mode == &#39;rigid&#39;:
                    icp = icp_transform(target=vtk_mesh_target, source=vtk_mesh_source, transform_mode=&#39;rigid&#39;)
                elif icp_registration_mode == &#39;similarity&#39;:
                    icp = icp_transform(target=vtk_mesh_target, source=vtk_mesh_source, transform_mode=&#39;similarity&#39;)
                vtk_mesh_source = apply_transform(source=vtk_mesh_source, transform=icp)
        print(&#39;Starting to build first graph&#39;)
        # Build target graph
        self.graph_target = Graph(vtk_mesh_target,
                                  n_spectral_features=self.n_total_spectral_features,
                                  n_rand_samples=n_coords_spectral_ordering,
                                  list_features_to_calc=list_features_to_calc,
                                  list_features_to_get_from_mesh=list_features_to_get_from_mesh,
                                  feature_weights=feature_weights,
                                  include_features_in_G_matrix=use_features_in_graph,
                                  include_features_in_adj_matrix=include_features_in_adj_matrix,
                                  G_matrix_p_function=G_matrix_p_function,
                                  norm_node_features_std=norm_node_features_std,
                                  norm_node_features_cap_std=norm_node_features_cap_std,
                                  norm_node_features_0_1=norm_node_features_0_1
                                  )
        print(&#39;Loaded Mesh 1&#39;)
        # Build target spectrum
        self.graph_target.get_graph_spectrum()
        print(&#39;Computed spectrum 1&#39;)
        # Build source graph
        self.graph_source = Graph(vtk_mesh_source,
                                  n_spectral_features=self.n_total_spectral_features,
                                  n_rand_samples=n_coords_spectral_ordering,
                                  list_features_to_calc=list_features_to_calc,
                                  list_features_to_get_from_mesh=list_features_to_get_from_mesh,
                                  feature_weights=feature_weights,
                                  include_features_in_G_matrix=use_features_in_graph,
                                  include_features_in_adj_matrix=include_features_in_adj_matrix,
                                  G_matrix_p_function=G_matrix_p_function,
                                  norm_node_features_std=norm_node_features_std,
                                  norm_node_features_cap_std=norm_node_features_cap_std,
                                  norm_node_features_0_1=norm_node_features_0_1,
                                  )
        print(&#39;Loaded Mesh 2&#39;)
        # Build source spectrum
        self.graph_source.get_graph_spectrum()
        print(&#39;Computed spectrum 2&#39;)

        # Define / specify parameters to be used.
        # Spectral alignment related
        self.Q = None
        self.spec_weights = None
        self.source_spectral_coords = None  # Could pre-allocate using np.zeros()
        self.target_spectral_coords = None  # Could pre-allocate using np.zeros()

        # Extra features (curvature etc.)
        self.source_extra_features = None  # Extra features used for mapping
        self.target_extra_features = None
        self.use_features_as_coords = use_features_as_coords

        # Saved versions of spectral coords during registration/processing for post-analysis/viewing
        self.source_spectral_coords_after_rigid = None
        self.source_spectral_coords_b4_reg = None

        # saved registration parameters - not currently used for anything. Could be used to transform points after
        # the fact.
        self.rigid_params = None
        self.non_rigid_params = None

        # Results / Correspondences:

        self.smoothed_target_coords = None       # smoothed coordinates of target - used for final correspondences.
        self.source_projected_on_target = None   # source values projected on target graph for finding final correspond
        self.weighted_avg_transformed_mesh = None  # source mesh transformed to target w/ weighted avg.
        self.nearest_neighbour_transformed_mesh = None  # source mesh transformed to target w/ nearest neighbour
        self.corresponding_target_idx_for_each_source_pt = None  # Final correspondence (target ID for each source pt)
        self.nearest_neighbor_transformed_points = None  # location source points move on target as nearest neighbor.
        self.weighted_avg_transformed_points = None  # location source points move on the target mesh as weighted avg.
        self.average_mesh = None  # average of the two meshes (based on the correspondences).
        # self.nearest_neighbour_transformed_mesh = None
        # self.weighted_avg_transformed_mesh = None
        # NEED ONE MORE OUTSPUTS:
        # MESH REPRESENTING MEAN OF TWO MESHES

    &#34;&#34;&#34;
    Functions to prepare pointsets to be registered. 
    &#34;&#34;&#34;

    def append_features_to_spectral_coords(self):
        print(&#39;Appending Extra Features to Spectral Coords&#39;)
        if self.graph_source.n_extra_features != self.graph_target.n_extra_features:
            raise Exception(&#39;Number of extra features between&#39;
                            &#39; target ({}) and source ({}) dont match!&#39;.format(self.graph_target.n_extra_features,
                                                                              self.graph_source.n_extra_features))

        self.source_extra_features = np.zeros((self.graph_source.n_points, self.graph_source.n_extra_features))
        self.target_extra_features = np.zeros((self.graph_target.n_points, self.graph_target.n_extra_features))

        for feature_idx in range(self.graph_source.n_extra_features):
            self.source_extra_features[:, feature_idx] = self.graph_source.mean_filter_graph(
                self.graph_source.node_features[feature_idx], iterations=self.feature_smoothing_iterations)
            self.source_extra_features[:, feature_idx] = self.source_extra_features[:, feature_idx] \
                                                         - np.min(self.source_extra_features[:, feature_idx])
            self.source_extra_features[:, feature_idx] = self.source_extra_features[:, feature_idx] \
                                                         / np.max(self.source_extra_features[:, feature_idx])
            self.source_extra_features[:, feature_idx] = np.ptp(self.source_spectral_coords) * self.source_extra_features[:, feature_idx]

            self.target_extra_features[:, feature_idx] = self.graph_target.mean_filter_graph(
                self.graph_target.node_features[feature_idx], iterations=self.feature_smoothing_iterations)
            self.target_extra_features[:, feature_idx] = self.target_extra_features[:, feature_idx] \
                                                         - np.min(self.target_extra_features[:, feature_idx])
            self.target_extra_features[:, feature_idx] = self.target_extra_features[:, feature_idx] \
                                                         / np.max(self.target_extra_features[:, feature_idx])
            self.target_extra_features[:, feature_idx] = np.ptp(
                self.target_spectral_coords) * self.target_extra_features[:, feature_idx]

        self.source_spectral_coords = np.concatenate((self.source_spectral_coords,
                                                      self.source_extra_features), axis=1)
        self.target_spectral_coords = np.concatenate((self.target_spectral_coords,
                                                      self.target_extra_features), axis=1)

    def append_pts_to_spectral_coords(self):
        if self.norm_physical_and_spectral is True:
            self.source_spectral_coords = np.concatenate((self.source_spectral_coords,
                                                          self.graph_source.normed_points), axis=1)
            self.target_spectral_coords = np.concatenate((self.target_spectral_coords,
                                                          self.graph_target.normed_points), axis=1)
        elif self.norm_physical_and_spectral is False:
            # If we dont scale everything down to be 0-1, then assume that we scale everything up to be the same
            # dimensions/range as the original image.
            self.source_spectral_coords = np.concatenate((self.source_spectral_coords
                                                          * self.graph_source.mean_pts_scale_range,
                                                          self.graph_source.points), axis=1)
            self.target_spectral_coords = np.concatenate((self.target_spectral_coords
                                                          * self.graph_target.mean_pts_scale_range,
                                                          self.graph_target.points), axis=1)

    def register_target_to_source(self, reg_type=&#39;deformable&#39;):
        if reg_type == &#39;deformable&#39;:
            reg = cycpd.deformable_registration(**{
                &#39;X&#39;: self.source_spectral_coords[
                     self.graph_source.get_list_rand_idxs(self.n_coords_spectral_registration), :],
                &#39;Y&#39;: self.target_spectral_coords[
                     self.graph_target.get_list_rand_idxs(self.n_coords_spectral_registration), :],
                &#39;num_eig&#39;: self.non_rigid_n_eigens,
                &#39;max_iterations&#39;: self.non_rigid_max_iterations,
                &#39;tolerance&#39;: self.non_rigid_tolerance,
                &#39;alpha&#39;: self.non_rigid_alpha,
                &#39;beta&#39;: self.non_rigid_beta
            }
                                                          )
            _, self.non_rigid_params = reg.register()
        elif reg_type == &#39;affine&#39;:
            # Using affine instead of truly rigid, because rigid doesnt accept &gt;3 dimensions at moment.
            reg = cycpd.affine_registration(**{
                &#39;X&#39;: self.source_spectral_coords[
                     self.graph_source.get_list_rand_idxs(self.n_coords_spectral_registration), :],
                &#39;Y&#39;: self.target_spectral_coords[
                     self.graph_target.get_list_rand_idxs(self.n_coords_spectral_registration), :],
                &#39;max_iterations&#39;: self.rigid_reg_max_iterations,
                &#39;tolerance&#39;: self.rigid_tolerance
            }
                                                  )
            _, self.rigid_params = reg.register()

        # Apply transform to all points (ensures all points are transformed even if not all used for registration).
        self.target_spectral_coords = reg.transform_point_cloud(self.target_spectral_coords)

    &#34;&#34;&#34;
    Functions to find correspondences between arrays of points. 
    &#34;&#34;&#34;

    def get_hungarian_correspondence(self, target_pts, spectral_pts):
        tic = time.time()
        distances = cdist(spectral_pts, target_pts)
        toc = time.time()
        print(&#39;time to get cdist: {}&#39;.format(toc - tic))
        tic = time.time()
        source_idx, target_idx = linear_sum_assignment(distances)
        toc = time.time()
        print(&#39;time to linear sum assignment: {}&#39;.format(toc - tic))
        self.corresponding_target_idx_for_each_source_pt = target_idx

    def get_kd_correspondence(self, target_pts, spectral_pts):
        tree = KDTree(target_pts)
        _, self.corresponding_target_idx_for_each_source_pt = tree.query(spectral_pts)

    def get_initial_correspondences(self):
        &#34;&#34;&#34;
        Find target idx that is closest to each source point.
        The correspondences indicate where (on the target mesh) each source point should move to.
        :return:
        &#34;&#34;&#34;
        if self.initial_correspondence_type == &#39;kd&#39;:
            self.get_kd_correspondence(self.target_spectral_coords, self.source_spectral_coords)
        elif self.initial_correspondence_type == &#39;hungarian&#39;:
            self.get_hungarian_correspondence(self.target_spectral_coords, self.source_spectral_coords)

    def get_smoothed_correspondences(self):
        # Smooth the XYZ vertices using adjacency matrix for target
        # This will filter the target points using a low-pass filter
        self.smoothed_target_coords = self.graph_target.mean_filter_graph(self.graph_target.points,
                                                                          iterations=self.graph_smoothing_iterations)
        # Next, we take each of these smoothed points (particularly arranged based on which ones best align with
        # the spectral coordinates of the target mesh) and we smooth these vertices/values using the adjacency/degree
        # matrix of the source mesh. I.e. the target mesh coordinates are smoothed on the surface of the source mesh.
        if ((self.smoothed_target_coords.shape[0] != self.graph_source.n_points)
                &amp; (self.initial_correspondence_type == &#39;hungarian&#39;)):
            raise Exception(&#34;If number vertices between source &amp; target don&#39;t match, initial_correspondence_type must\n&#34;
                            &#34;be &#39;kd&#39; and not &#39;hungarian&#39;. Current type is: {}&#34;.format(self.initial_correspondence_type))
        self.source_projected_on_target = self.graph_source.mean_filter_graph(self.smoothed_target_coords[self.corresponding_target_idx_for_each_source_pt, :],
                                                                              iterations=self.projection_smooth_iterations)

        if self.final_correspondence_type == &#39;kd&#39;:
            self.get_kd_correspondence(self.smoothed_target_coords, self.source_projected_on_target)
        elif self.final_correspondence_type == &#39;hungarian&#39;:
            self.get_hungarian_correspondence(self.smoothed_target_coords, self.source_projected_on_target)

        # This now matches/makes correspondences. Can use this correspondence.
        # Or can associate with points in between these points...

    def get_weighted_final_node_locations(self, n_closest_pts=3):
        &#34;&#34;&#34;
        Disperse points (from source) over the target mesh surface - distribute them instead of just finding the
        closest point.
        :return:
        &#34;&#34;&#34;
        self.weighted_avg_transformed_points = np.zeros_like(self.graph_source.points)

        tree = KDTree(self.smoothed_target_coords)
        for pt_idx in range(self.graph_source.n_points):
            closest_pt_distances, closest_pt_idxs = tree.query(self.source_projected_on_target[pt_idx, :],
                                                               k=n_closest_pts)

            if 0 in closest_pt_distances:
                idx_coincident = np.where(closest_pt_distances == 0)[0][0]
                self.weighted_avg_transformed_points[pt_idx, :] = self.graph_target.points[closest_pt_idxs[idx_coincident]]
            else:
                weighting = 1 / closest_pt_distances[:, None]

                avg_location = np.sum(self.graph_target.points[closest_pt_idxs, :] * weighting, axis=0) / (sum(weighting))
                self.weighted_avg_transformed_points[pt_idx, :] = avg_location

    def get_nearest_neighbour_final_node_locations(self):
        self.nearest_neighbor_transformed_points = self.graph_target.points[self.corresponding_target_idx_for_each_source_pt, :]

    def get_average_shape(self, align_type=&#39;weighted&#39;):
        &#34;&#34;&#34;
        Get new mesh average of the transformed source &amp; target.
        :return:
        &#34;&#34;&#34;
        self.average_mesh = vtk_deep_copy(self.graph_source.vtk_mesh)

        points = self.average_mesh.GetPoints()
        if align_type == &#39;nearest&#39;:
            for src_pt_idx in range(self.graph_source.n_points):
                trget_pt_idx = self.corresponding_target_idx_for_each_source_pt[src_pt_idx]
                new_xyz = self.graph_target.vtk_mesh.GetPoint(trget_pt_idx)
                orig_xyz = self.graph_source.points[src_pt_idx]
                mean_xyz = (orig_xyz + new_xyz) / 2
                points.SetPoint(src_pt_idx, mean_xyz)
        elif align_type == &#39;weighted&#39;:
            for src_pt_idx in range(self.graph_source.n_points):
                orig_xyz = self.weighted_avg_transformed_points[src_pt_idx]
                new_xyz = self.graph_source.points[src_pt_idx]
                mean_xyz = (orig_xyz + new_xyz) / 2
                points.SetPoint(src_pt_idx, mean_xyz)


    &#34;&#34;&#34;
    Spectral Weighting
    &#34;&#34;&#34;

    def calc_c_weighting_spectral(self):
        &#34;&#34;&#34;
        calculate spectral weighting coefficient. If 10 spectral coorindates (per point), would calculate
        10 weighting coefficients to weight importance of these coordinates.

        c^(u) = exp( -(Q^u * lambda^u)^2 / 2sigma^2)

        lambda^u = uth eigenvalue and represents smoothness of eigenvector (spectral coordinates)
        Q^u = confidence in re-ordered postion of uth set of eigenvactors, eigenvalues - from the dissimilarity
            matrix Q.
        sigma = mean {Q^u * lambda^u} subscript (u=1...m)


        Because this step is finally done with re-ordering etc. We should probably use only the n spectral coords that
        we intend to use for the analysis.



        :return:
        &#34;&#34;&#34;

        # highest eigenvalue weight from the two meshes (for a given pair).
        self.spectral_weights = self.Q[:self.n_spectral_features] \
                                * np.max((self.graph_source.eig_vals[:self.n_spectral_features],
                                      self.graph_target.eig_vals[:self.n_spectral_features]),
                                      axis=0)
        # Q is a weighting factor to get the mean weight (across the different spectral coordinates).
        sigma = np.mean(self.spectral_weights)
        self.spectral_weights = np.exp(-(self.spectral_weights ** 2) / (2 * sigma ** 2))

    def calc_weighted_spectral_coords(self):
        self.calc_c_weighting_spectral()
        self.source_spectral_coords = self.graph_source.eig_vecs[:, :self.n_spectral_features] \
                                      * self.spectral_weights[None, :]
        self.target_spectral_coords = self.graph_target.eig_vecs[:, :self.n_spectral_features] \
                                      * self.spectral_weights[None, :]

    def calc_spectral_coords(self):
        if self.get_weighted_spectral_coords is True:
            self.calc_weighted_spectral_coords()
        elif self.get_weighted_spectral_coords is False:
            self.source_spectral_coords = self.graph_source.eig_vecs[:, :self.n_spectral_features]
            self.target_spectral_coords = self.graph_target.eig_vecs[:, :self.n_spectral_features]

    &#34;&#34;&#34;
    Align Maps
    &#34;&#34;&#34;

    def align_maps(self):
        eig_map_sorter = eigsort(graph_target=self.graph_target,
                                 graph_source=self.graph_source,
                                 n_features=self.n_total_spectral_features,
                                 target_as_reference=self.target_eigenmap_as_reference)
        self.Q = eig_map_sorter.sort_eigenmaps()
        self.calc_spectral_coords()

        if (self.graph_source.n_extra_features &gt; 0) &amp; (self.use_features_as_coords is True):
            self.append_features_to_spectral_coords()

        if self.include_points_as_features is True:
            self.append_pts_to_spectral_coords()

        self.source_spectral_coords_b4_reg = np.copy(self.source_spectral_coords)

        print(&#39;Number of features (including spectral) &#39;
              &#39;used for registartion: {}&#39;.format(self.target_spectral_coords.shape[1]))

        if self.rigid_before_non_rigid_reg is True:
            print_header(&#39;Rigid Registration Beginning!&#39;)
            self.register_target_to_source(reg_type=&#39;affine&#39;)
            self.source_spectral_coords_after_rigid = np.copy(self.source_spectral_coords)

        print_header(&#39;Non-Rigid (Deformable) Registration Beginning&#39;)
        self.register_target_to_source(&#39;deformable&#39;)

        self.get_initial_correspondences()
        print(&#39;Number of unique correspondences: {}&#39;.format(len(np.unique(self.corresponding_target_idx_for_each_source_pt))
                                                            ))
        if self.smooth_correspondences is True:
            self.get_smoothed_correspondences()
            print(&#39;Number of unique correspondences after smoothing: {}&#39;.format(
                len(np.unique(self.corresponding_target_idx_for_each_source_pt))
                ))

        if self.return_average_final_points is True:
            self.get_weighted_final_node_locations()
        if self.return_nearest_final_points is True:
            self.get_nearest_neighbour_final_node_locations()

        if self.return_transformed_mesh is True:
            if self.return_average_final_points is True:
                self.get_source_mesh_transformed_weighted_avg()
            if self.return_nearest_final_points is True:
                self.get_source_mesh_transformed_nearest_neighbour()

        # return self.corresponding_target_idx_for_each_source_pt

    &#34;&#34;&#34;
    Change mesh scalar values (for visualizations). 
    &#34;&#34;&#34;

    def set_transformed_source_scalars_to_corresp_target_idx(self):
        if self.weighted_avg_transformed_mesh is not None:
            self.weighted_avg_transformed_mesh.GetPointData().SetScalars(
            numpy_to_vtk(self.corresponding_target_idx_for_each_source_pt))
        if self.nearest_neighbour_transformed_mesh is not None:
            self.nearest_neighbour_transformed_mesh.GetPointData().SetScalars(
            numpy_to_vtk(self.corresponding_target_idx_for_each_source_pt))

    def set_source_scalars_to_corresp_target_idx(self):
        self.graph_source.vtk_mesh.GetPointData().SetScalars(
            numpy_to_vtk(self.corresponding_target_idx_for_each_source_pt))

    def set_target_scalars_to_corresp_target_idx(self):
        self.graph_target.vtk_mesh.GetPointData().SetScalars(
            numpy_to_vtk(np.arange(self.graph_target.n_points)))

    def set_all_mesh_scalars_to_corresp_target_idx(self):
        self.set_target_scalars_to_corresp_target_idx()
        self.set_source_scalars_to_corresp_target_idx()
        self.set_transformed_source_scalars_to_corresp_target_idx()

    &#34;&#34;&#34;
    Probing &amp; View Results
    &#34;&#34;&#34;
    def get_source_mesh_transformed_weighted_avg(self):
        &#34;&#34;&#34;
        Create new mesh same as source mesh. Get source points. Move source points to transformed location(s) on
        target mesh using weighted average locations.
        :return:
        &#34;&#34;&#34;
        self.weighted_avg_transformed_mesh = vtk_deep_copy(self.graph_source.vtk_mesh)
        points = self.weighted_avg_transformed_mesh.GetPoints()
        for src_pt_idx in range(self.graph_source.n_points):
            points.SetPoint(src_pt_idx, self.weighted_avg_transformed_points[src_pt_idx])

    def get_source_mesh_transformed_nearest_neighbour(self):
        &#34;&#34;&#34;
        Create new mesh same as source mesh. Get source points. Move source points to transformed location(s) on
        target mesh using nearest neighbour locations.
        :return:
        &#34;&#34;&#34;
        self.nearest_neighbour_transformed_mesh = vtk_deep_copy(self.graph_source.vtk_mesh)
        points = self.nearest_neighbour_transformed_mesh.GetPoints()
        for src_pt_idx in range(self.graph_source.n_points):
            points.SetPoint(src_pt_idx, self.nearest_neighbor_transformed_points[src_pt_idx])

    # def get_source_mesh_transformed(self):
    #     &#34;&#34;&#34;
    #     Create new mesh same as source mesh. Get source points. Move source points to transformed location(s) on
    #     target mesh.
    #     :return:
    #     &#34;&#34;&#34;
    #     self.source_vtk_mesh_transformed = vtk_deep_copy(self.graph_source.vtk_mesh)
    #     points = self.source_vtk_mesh_transformed.GetPoints()
    #
    #     points = self.source_vtk_mesh_transformed.GetPoints()
    #     if self.diffuse_final_points is False:
    #         for src_pt_idx in range(self.graph_source.n_points):
    #             trget_pt_idx = self.corresponding_target_idx_for_each_source_pt[src_pt_idx]
    #             trget_pt_xyz = self.graph_target.vtk_mesh.GetPoint(trget_pt_idx)
    #             points.SetPoint(src_pt_idx, trget_pt_xyz)
    #     elif self.diffuse_final_points is True:
    #         for src_pt_idx in range(self.graph_source.n_points):
    #             points.SetPoint(src_pt_idx, self.weighted_avg_transformed_points[src_pt_idx])


    def view_aligned_spectral_coords(self, starting_spectral_coord=0,
                                     point_set_representations=[&#39;spheres&#39;],
                                     point_set_colors=None,
                                     include_target_coordinates=True,
                                     include_non_rigid_aligned=True,
                                     include_rigid_aligned=False,
                                     include_unaligned=False,
                                     upscale_factor=10.
                                     ):

        point_sets = []

        if include_target_coordinates is True:
            point_sets.append(upscale_factor
                              * np.ascontiguousarray(self.target_spectral_coords[:, starting_spectral_coord:starting_spectral_coord + 3]))

        if include_unaligned is True:
            point_sets.append(upscale_factor
                              * np.ascontiguousarray(self.source_spectral_coords_b4_reg[:, starting_spectral_coord:starting_spectral_coord + 3]))

        if include_rigid_aligned is True:
            point_sets.append(upscale_factor
                              * np.ascontiguousarray(self.source_spectral_coords_after_rigid[:, starting_spectral_coord:starting_spectral_coord + 3]))

        if include_non_rigid_aligned is True:
            point_sets.append(upscale_factor
                              * np.ascontiguousarray(self.source_spectral_coords[:, starting_spectral_coord:starting_spectral_coord+3]))

        # Make all the same shape, if only one specified and more than one point et included.
        if (len(point_set_representations) == 1) &amp; (len(point_sets) &gt; 1):
            point_set_representations = point_set_representations * len(point_sets)

        # Colours points sets sequentially using matplotlib V2 colours:
        if point_set_colors is None:
            point_set_colors = [colors.to_rgb(&#39;C{}&#39;.format(x)) for x in range(len(point_sets))]
        plotter = Viewer(point_sets=point_sets,
                         point_set_representations=point_set_representations,
                         point_set_colors=point_set_colors
                         )

        return plotter

    def view_meshes_colored_by_spectral_correspondences(self,
                                                        x_translation=100,
                                                        y_translation=0,
                                                        z_translation=0,
                                                        shadow=True):
        target_mesh = vtk_deep_copy(self.graph_target.vtk_mesh)
        target_mesh.GetPointData().SetScalars(numpy_to_vtk(np.arange(self.graph_target.n_points)))

        source_mesh = vtk_deep_copy(self.graph_source.vtk_mesh)
        source_mesh.GetPointData().SetScalars(numpy_to_vtk(self.corresponding_target_idx_for_each_source_pt))

        target_transform = vtk.vtkTransform()
        target_transform.Translate(x_translation, y_translation, z_translation)
        target_mesh = apply_transform(target_mesh, target_transform)

        plotter = Viewer(geometries=[source_mesh, target_mesh], shadow=shadow)
        return plotter

    def view_aligned_smoothed_spectral_coords(self):
        plotter = Viewer(point_sets=[self.smoothed_target_coords, self.source_projected_on_target],
                         point_set_colors=[colors.to_rgb(&#39;C0&#39;), colors.to_rgb(&#39;C1&#39;)])
        return plotter

    def view_meshes(self, include_target=True,
                    include_source=True,
                    include_transformed_target=False,
                    include_average=False,
                    shadow=True
                    ):
        geometries = []
        if include_target is True:
            geometries.append(self.graph_target.vtk_mesh)
        if include_source is True:
            geometries.append(self.graph_source.vtk_mesh)
        if include_transformed_target is True:
            if self.weighted_avg_transformed_mesh is not None:
                geometries.append(self.weighted_avg_transformed_mesh)
            elif self.nearest_neighbour_transformed_mesh is not None:
                geometries.append(self.nearest_neighbour_transformed_mesh)
            elif self.weighted_avg_transformed_points is not None:
                self.get_weighted_final_node_locations()
                self.get_source_mesh_transformed_weighted_avg()
                geometries.append(self.weighted_avg_transformed_mesh)
            elif self.nearest_neighbor_transformed_points is not None:
                self.get_nearest_neighbour_final_node_locations()
                self.get_source_mesh_transformed_nearest_neighbour()
                geometries.append(self.nearest_neighbour_transformed_mesh)
            else:
                raise Exception(&#39;No corresponding points or meshes calculated. Try running: \n&#39;
                                &#39;reg.get_weighted_final_node_locations()\n&#39;
                                &#39;reg.get_nearest_neighbour_final_node_locations()\n&#39;
                                &#39;or try re-running with the flags: \n&#39;
                                &#39;return_average_final_points=True &amp; return_transformed_mesh=True&#39;)
        if include_average is True:
            if self.average_mesh is None:
                if self.weighted_avg_transformed_points is not None:
                    self.get_average_shape()
                elif self.nearest_neighbor_transformed_points is not None:
                    self.get_average_shape(align_type=&#39;nearest&#39;)
                else:
                    raise Exception(&#34;No xyz correspondences calculated can&#39;t get average! Try:\n&#34;
                                    &#34;`reg.get_weighted_final_node_locations` or `reg.get_nearest_neighbour_final_node_locations`&#34;)
            geometries.append(self.average_mesh)

        plotter = Viewer(geometries=geometries, shadow=shadow)
        return plotter</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="pyfocusr.focusr.Focusr"><code class="flex name class">
<span>class <span class="ident">Focusr</span></span>
<span>(</span><span>vtk_mesh_target, vtk_mesh_source, icp_register_first=True, icp_registration_mode='rigid', icp_reg_target_to_source=False, n_spectral_features=3, n_extra_spectral=3, target_eigenmap_as_reference=True, norm_physical_and_spectral=True, n_coords_spectral_ordering=5000, n_coords_spectral_registration=5000, rigid_before_non_rigid_reg=True, rigid_reg_max_iterations=100, rigid_tolerance=1e-08, non_rigid_max_iterations=1000, non_rigid_tolerance=1e-08, non_rigid_alpha=0.5, non_rigid_beta=3.0, non_rigid_n_eigens=100, include_points_as_features=False, get_weighted_spectral_coords=True, graph_smoothing_iterations=300, feature_smoothing_iterations=40, smooth_correspondences=True, return_average_final_points=True, return_nearest_final_points=True, return_transformed_mesh=True, projection_smooth_iterations=40, feature_weights=None, initial_correspondence_type='kd', final_correspondence_type='kd', list_features_to_calc=['curvature'], list_features_to_get_from_mesh=[], use_features_as_coords=False, use_features_in_graph=False, include_features_in_adj_matrix=False, G_matrix_p_function='exp', norm_node_features_std=True, norm_node_features_cap_std=3, norm_node_features_0_1=True, verbose=False)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Focusr(object):
    def __init__(self,
                 vtk_mesh_target,
                 vtk_mesh_source,
                 icp_register_first=True,               # bool, should register meshes together first
                 icp_registration_mode=&#39;rigid&#39;,         # str - should icp reg be rigid or similarity (rigid + scale)
                 icp_reg_target_to_source=False,        # bool of what should be registered to what in ICP.
                 n_spectral_features=3,                 #
                 n_extra_spectral=3,                    #
                 target_eigenmap_as_reference=True,     # bool, should use target eigenmap as reference for spectral reg
                                                        # This is helpful for registering a &#34;template&#34; mesh (which is the source)
                                                        # to another mesh (which is the target), commonly performed in
                                                        # statistical shape models (SSM).
                 norm_physical_and_spectral=True,       #
                 n_coords_spectral_ordering=5000,       #
                 n_coords_spectral_registration=5000,   #
                 rigid_before_non_rigid_reg=True,       #
                 rigid_reg_max_iterations=100,          #
                 rigid_tolerance=1e-8,                  #
                 non_rigid_max_iterations=1000,         #
                 non_rigid_tolerance=1e-8,              #
                 non_rigid_alpha=0.5,                   #
                 non_rigid_beta=3.0,                    #
                 non_rigid_n_eigens=100,                #
                 include_points_as_features=False,      #
                 get_weighted_spectral_coords=True,     #
                 graph_smoothing_iterations=300,        #
                 feature_smoothing_iterations=40,       #
                 smooth_correspondences=True,           #
                 return_average_final_points=True,      # should we create diffused/weighted new points
                 return_nearest_final_points=True,      # should we create nearest neighbor new points.
                 return_transformed_mesh=True,          #
                 projection_smooth_iterations=40,       #
                 feature_weights=None,                  #
                 initial_correspondence_type=&#39;kd&#39;,      # &#39;kd&#39; or &#39;hungarian&#39;
                 final_correspondence_type=&#39;kd&#39;,        #
                 list_features_to_calc=[&#39;curvature&#39;],   # include as input of graph_source &amp; graph_target
                 list_features_to_get_from_mesh=[],     # &#39;thickness (mm)&#39; - get info from mesh surface for reg
                 use_features_as_coords=False,          #
                 use_features_in_graph=False,           #
                 include_features_in_adj_matrix=False,  # include as input of graph_source &amp; graph_target
                 G_matrix_p_function=&#39;exp&#39;,             # Param for feature processing before laplacian creation
                 norm_node_features_std=True,           # Param for feature processing before laplacian creation
                 norm_node_features_cap_std=3,          # Param for feature processing before laplacian creation
                 norm_node_features_0_1=True,           # Param for feature processing before laplacian creation
                 verbose=False                          # bool - setting whether should print extraneous details
                 ):
        self.verbose = verbose
        print(&#39;Starting Focusr&#39;)
        # Inputs
        #   Spectral coordinates based inputs/parameters
        self.n_spectral_features = n_spectral_features
        self.n_extra_spectral = n_extra_spectral
        self.n_total_spectral_features = self.n_spectral_features + self.n_extra_spectral
        self.target_eigenmap_as_reference = target_eigenmap_as_reference

        #   Normalization &amp; what included in registration
        self.norm_physical_and_spectral = norm_physical_and_spectral  # Bool, norm spect&amp;xyz. Otherwise, spect to xyz.
        self.include_points_as_features = include_points_as_features  # include xyz coords in registration
        self.get_weighted_spectral_coords = get_weighted_spectral_coords
        self.feature_smoothing_iterations = feature_smoothing_iterations  # number smooth iterations to extra features
        #   Registration parameters (general)
        self.n_coords_spectral_registration = n_coords_spectral_registration  # max n points for registration
        #       Rigid reg params
        self.rigid_before_non_rigid_reg = rigid_before_non_rigid_reg
        self.rigid_reg_max_iterations = rigid_reg_max_iterations
        self.rigid_tolerance = rigid_tolerance
        #       Deformable reg params
        self.non_rigid_max_iterations = non_rigid_max_iterations
        self.non_rigid_tolerance = non_rigid_tolerance
        self.non_rigid_alpha = non_rigid_alpha
        self.non_rigid_beta = non_rigid_beta
        self.non_rigid_n_eigens = non_rigid_n_eigens
        #   Correspondence selection parameters
        self.initial_correspondence_type = initial_correspondence_type
        self.smooth_correspondences = smooth_correspondences  # Bool - smooth values to improve diffeomorphism?
        self.return_average_final_points = return_average_final_points  # make weighted avg final xyz position?
        self.return_nearest_final_points = return_nearest_final_points  # make nearest neighbour final xyz position?
        self.graph_smoothing_iterations = graph_smoothing_iterations
        self.projection_smooth_iterations = projection_smooth_iterations  # n iterations projection smoothing
        self.final_correspondence_type = final_correspondence_type  # &#39;kd&#39; or &#39;hungarian&#39; correspondence
        self.return_transformed_mesh = return_transformed_mesh  # bool to tell if we should create new mesh.

        print(&#39;Starting ICP&#39;)
        # Prepare Meshes / Graphs
        #   Rigidly register target to source before beginning.
        #   This ensures they are in same space for all steps.
        if icp_register_first is True:
            if icp_reg_target_to_source is True:
                if icp_registration_mode == &#39;rigid&#39;:
                    icp = icp_transform(target=vtk_mesh_source, source=vtk_mesh_target, transform_mode=&#39;rigid&#39;)
                elif icp_registration_mode == &#39;similarity&#39;:
                    icp = icp_transform(target=vtk_mesh_source, source=vtk_mesh_target, transform_mode=&#39;similarity&#39;)
                vtk_mesh_target = apply_transform(source=vtk_mesh_target, transform=icp)
            elif icp_reg_target_to_source is False:
                if icp_registration_mode == &#39;rigid&#39;:
                    icp = icp_transform(target=vtk_mesh_target, source=vtk_mesh_source, transform_mode=&#39;rigid&#39;)
                elif icp_registration_mode == &#39;similarity&#39;:
                    icp = icp_transform(target=vtk_mesh_target, source=vtk_mesh_source, transform_mode=&#39;similarity&#39;)
                vtk_mesh_source = apply_transform(source=vtk_mesh_source, transform=icp)
        print(&#39;Starting to build first graph&#39;)
        # Build target graph
        self.graph_target = Graph(vtk_mesh_target,
                                  n_spectral_features=self.n_total_spectral_features,
                                  n_rand_samples=n_coords_spectral_ordering,
                                  list_features_to_calc=list_features_to_calc,
                                  list_features_to_get_from_mesh=list_features_to_get_from_mesh,
                                  feature_weights=feature_weights,
                                  include_features_in_G_matrix=use_features_in_graph,
                                  include_features_in_adj_matrix=include_features_in_adj_matrix,
                                  G_matrix_p_function=G_matrix_p_function,
                                  norm_node_features_std=norm_node_features_std,
                                  norm_node_features_cap_std=norm_node_features_cap_std,
                                  norm_node_features_0_1=norm_node_features_0_1
                                  )
        print(&#39;Loaded Mesh 1&#39;)
        # Build target spectrum
        self.graph_target.get_graph_spectrum()
        print(&#39;Computed spectrum 1&#39;)
        # Build source graph
        self.graph_source = Graph(vtk_mesh_source,
                                  n_spectral_features=self.n_total_spectral_features,
                                  n_rand_samples=n_coords_spectral_ordering,
                                  list_features_to_calc=list_features_to_calc,
                                  list_features_to_get_from_mesh=list_features_to_get_from_mesh,
                                  feature_weights=feature_weights,
                                  include_features_in_G_matrix=use_features_in_graph,
                                  include_features_in_adj_matrix=include_features_in_adj_matrix,
                                  G_matrix_p_function=G_matrix_p_function,
                                  norm_node_features_std=norm_node_features_std,
                                  norm_node_features_cap_std=norm_node_features_cap_std,
                                  norm_node_features_0_1=norm_node_features_0_1,
                                  )
        print(&#39;Loaded Mesh 2&#39;)
        # Build source spectrum
        self.graph_source.get_graph_spectrum()
        print(&#39;Computed spectrum 2&#39;)

        # Define / specify parameters to be used.
        # Spectral alignment related
        self.Q = None
        self.spec_weights = None
        self.source_spectral_coords = None  # Could pre-allocate using np.zeros()
        self.target_spectral_coords = None  # Could pre-allocate using np.zeros()

        # Extra features (curvature etc.)
        self.source_extra_features = None  # Extra features used for mapping
        self.target_extra_features = None
        self.use_features_as_coords = use_features_as_coords

        # Saved versions of spectral coords during registration/processing for post-analysis/viewing
        self.source_spectral_coords_after_rigid = None
        self.source_spectral_coords_b4_reg = None

        # saved registration parameters - not currently used for anything. Could be used to transform points after
        # the fact.
        self.rigid_params = None
        self.non_rigid_params = None

        # Results / Correspondences:

        self.smoothed_target_coords = None       # smoothed coordinates of target - used for final correspondences.
        self.source_projected_on_target = None   # source values projected on target graph for finding final correspond
        self.weighted_avg_transformed_mesh = None  # source mesh transformed to target w/ weighted avg.
        self.nearest_neighbour_transformed_mesh = None  # source mesh transformed to target w/ nearest neighbour
        self.corresponding_target_idx_for_each_source_pt = None  # Final correspondence (target ID for each source pt)
        self.nearest_neighbor_transformed_points = None  # location source points move on target as nearest neighbor.
        self.weighted_avg_transformed_points = None  # location source points move on the target mesh as weighted avg.
        self.average_mesh = None  # average of the two meshes (based on the correspondences).
        # self.nearest_neighbour_transformed_mesh = None
        # self.weighted_avg_transformed_mesh = None
        # NEED ONE MORE OUTSPUTS:
        # MESH REPRESENTING MEAN OF TWO MESHES

    &#34;&#34;&#34;
    Functions to prepare pointsets to be registered. 
    &#34;&#34;&#34;

    def append_features_to_spectral_coords(self):
        print(&#39;Appending Extra Features to Spectral Coords&#39;)
        if self.graph_source.n_extra_features != self.graph_target.n_extra_features:
            raise Exception(&#39;Number of extra features between&#39;
                            &#39; target ({}) and source ({}) dont match!&#39;.format(self.graph_target.n_extra_features,
                                                                              self.graph_source.n_extra_features))

        self.source_extra_features = np.zeros((self.graph_source.n_points, self.graph_source.n_extra_features))
        self.target_extra_features = np.zeros((self.graph_target.n_points, self.graph_target.n_extra_features))

        for feature_idx in range(self.graph_source.n_extra_features):
            self.source_extra_features[:, feature_idx] = self.graph_source.mean_filter_graph(
                self.graph_source.node_features[feature_idx], iterations=self.feature_smoothing_iterations)
            self.source_extra_features[:, feature_idx] = self.source_extra_features[:, feature_idx] \
                                                         - np.min(self.source_extra_features[:, feature_idx])
            self.source_extra_features[:, feature_idx] = self.source_extra_features[:, feature_idx] \
                                                         / np.max(self.source_extra_features[:, feature_idx])
            self.source_extra_features[:, feature_idx] = np.ptp(self.source_spectral_coords) * self.source_extra_features[:, feature_idx]

            self.target_extra_features[:, feature_idx] = self.graph_target.mean_filter_graph(
                self.graph_target.node_features[feature_idx], iterations=self.feature_smoothing_iterations)
            self.target_extra_features[:, feature_idx] = self.target_extra_features[:, feature_idx] \
                                                         - np.min(self.target_extra_features[:, feature_idx])
            self.target_extra_features[:, feature_idx] = self.target_extra_features[:, feature_idx] \
                                                         / np.max(self.target_extra_features[:, feature_idx])
            self.target_extra_features[:, feature_idx] = np.ptp(
                self.target_spectral_coords) * self.target_extra_features[:, feature_idx]

        self.source_spectral_coords = np.concatenate((self.source_spectral_coords,
                                                      self.source_extra_features), axis=1)
        self.target_spectral_coords = np.concatenate((self.target_spectral_coords,
                                                      self.target_extra_features), axis=1)

    def append_pts_to_spectral_coords(self):
        if self.norm_physical_and_spectral is True:
            self.source_spectral_coords = np.concatenate((self.source_spectral_coords,
                                                          self.graph_source.normed_points), axis=1)
            self.target_spectral_coords = np.concatenate((self.target_spectral_coords,
                                                          self.graph_target.normed_points), axis=1)
        elif self.norm_physical_and_spectral is False:
            # If we dont scale everything down to be 0-1, then assume that we scale everything up to be the same
            # dimensions/range as the original image.
            self.source_spectral_coords = np.concatenate((self.source_spectral_coords
                                                          * self.graph_source.mean_pts_scale_range,
                                                          self.graph_source.points), axis=1)
            self.target_spectral_coords = np.concatenate((self.target_spectral_coords
                                                          * self.graph_target.mean_pts_scale_range,
                                                          self.graph_target.points), axis=1)

    def register_target_to_source(self, reg_type=&#39;deformable&#39;):
        if reg_type == &#39;deformable&#39;:
            reg = cycpd.deformable_registration(**{
                &#39;X&#39;: self.source_spectral_coords[
                     self.graph_source.get_list_rand_idxs(self.n_coords_spectral_registration), :],
                &#39;Y&#39;: self.target_spectral_coords[
                     self.graph_target.get_list_rand_idxs(self.n_coords_spectral_registration), :],
                &#39;num_eig&#39;: self.non_rigid_n_eigens,
                &#39;max_iterations&#39;: self.non_rigid_max_iterations,
                &#39;tolerance&#39;: self.non_rigid_tolerance,
                &#39;alpha&#39;: self.non_rigid_alpha,
                &#39;beta&#39;: self.non_rigid_beta
            }
                                                          )
            _, self.non_rigid_params = reg.register()
        elif reg_type == &#39;affine&#39;:
            # Using affine instead of truly rigid, because rigid doesnt accept &gt;3 dimensions at moment.
            reg = cycpd.affine_registration(**{
                &#39;X&#39;: self.source_spectral_coords[
                     self.graph_source.get_list_rand_idxs(self.n_coords_spectral_registration), :],
                &#39;Y&#39;: self.target_spectral_coords[
                     self.graph_target.get_list_rand_idxs(self.n_coords_spectral_registration), :],
                &#39;max_iterations&#39;: self.rigid_reg_max_iterations,
                &#39;tolerance&#39;: self.rigid_tolerance
            }
                                                  )
            _, self.rigid_params = reg.register()

        # Apply transform to all points (ensures all points are transformed even if not all used for registration).
        self.target_spectral_coords = reg.transform_point_cloud(self.target_spectral_coords)

    &#34;&#34;&#34;
    Functions to find correspondences between arrays of points. 
    &#34;&#34;&#34;

    def get_hungarian_correspondence(self, target_pts, spectral_pts):
        tic = time.time()
        distances = cdist(spectral_pts, target_pts)
        toc = time.time()
        print(&#39;time to get cdist: {}&#39;.format(toc - tic))
        tic = time.time()
        source_idx, target_idx = linear_sum_assignment(distances)
        toc = time.time()
        print(&#39;time to linear sum assignment: {}&#39;.format(toc - tic))
        self.corresponding_target_idx_for_each_source_pt = target_idx

    def get_kd_correspondence(self, target_pts, spectral_pts):
        tree = KDTree(target_pts)
        _, self.corresponding_target_idx_for_each_source_pt = tree.query(spectral_pts)

    def get_initial_correspondences(self):
        &#34;&#34;&#34;
        Find target idx that is closest to each source point.
        The correspondences indicate where (on the target mesh) each source point should move to.
        :return:
        &#34;&#34;&#34;
        if self.initial_correspondence_type == &#39;kd&#39;:
            self.get_kd_correspondence(self.target_spectral_coords, self.source_spectral_coords)
        elif self.initial_correspondence_type == &#39;hungarian&#39;:
            self.get_hungarian_correspondence(self.target_spectral_coords, self.source_spectral_coords)

    def get_smoothed_correspondences(self):
        # Smooth the XYZ vertices using adjacency matrix for target
        # This will filter the target points using a low-pass filter
        self.smoothed_target_coords = self.graph_target.mean_filter_graph(self.graph_target.points,
                                                                          iterations=self.graph_smoothing_iterations)
        # Next, we take each of these smoothed points (particularly arranged based on which ones best align with
        # the spectral coordinates of the target mesh) and we smooth these vertices/values using the adjacency/degree
        # matrix of the source mesh. I.e. the target mesh coordinates are smoothed on the surface of the source mesh.
        if ((self.smoothed_target_coords.shape[0] != self.graph_source.n_points)
                &amp; (self.initial_correspondence_type == &#39;hungarian&#39;)):
            raise Exception(&#34;If number vertices between source &amp; target don&#39;t match, initial_correspondence_type must\n&#34;
                            &#34;be &#39;kd&#39; and not &#39;hungarian&#39;. Current type is: {}&#34;.format(self.initial_correspondence_type))
        self.source_projected_on_target = self.graph_source.mean_filter_graph(self.smoothed_target_coords[self.corresponding_target_idx_for_each_source_pt, :],
                                                                              iterations=self.projection_smooth_iterations)

        if self.final_correspondence_type == &#39;kd&#39;:
            self.get_kd_correspondence(self.smoothed_target_coords, self.source_projected_on_target)
        elif self.final_correspondence_type == &#39;hungarian&#39;:
            self.get_hungarian_correspondence(self.smoothed_target_coords, self.source_projected_on_target)

        # This now matches/makes correspondences. Can use this correspondence.
        # Or can associate with points in between these points...

    def get_weighted_final_node_locations(self, n_closest_pts=3):
        &#34;&#34;&#34;
        Disperse points (from source) over the target mesh surface - distribute them instead of just finding the
        closest point.
        :return:
        &#34;&#34;&#34;
        self.weighted_avg_transformed_points = np.zeros_like(self.graph_source.points)

        tree = KDTree(self.smoothed_target_coords)
        for pt_idx in range(self.graph_source.n_points):
            closest_pt_distances, closest_pt_idxs = tree.query(self.source_projected_on_target[pt_idx, :],
                                                               k=n_closest_pts)

            if 0 in closest_pt_distances:
                idx_coincident = np.where(closest_pt_distances == 0)[0][0]
                self.weighted_avg_transformed_points[pt_idx, :] = self.graph_target.points[closest_pt_idxs[idx_coincident]]
            else:
                weighting = 1 / closest_pt_distances[:, None]

                avg_location = np.sum(self.graph_target.points[closest_pt_idxs, :] * weighting, axis=0) / (sum(weighting))
                self.weighted_avg_transformed_points[pt_idx, :] = avg_location

    def get_nearest_neighbour_final_node_locations(self):
        self.nearest_neighbor_transformed_points = self.graph_target.points[self.corresponding_target_idx_for_each_source_pt, :]

    def get_average_shape(self, align_type=&#39;weighted&#39;):
        &#34;&#34;&#34;
        Get new mesh average of the transformed source &amp; target.
        :return:
        &#34;&#34;&#34;
        self.average_mesh = vtk_deep_copy(self.graph_source.vtk_mesh)

        points = self.average_mesh.GetPoints()
        if align_type == &#39;nearest&#39;:
            for src_pt_idx in range(self.graph_source.n_points):
                trget_pt_idx = self.corresponding_target_idx_for_each_source_pt[src_pt_idx]
                new_xyz = self.graph_target.vtk_mesh.GetPoint(trget_pt_idx)
                orig_xyz = self.graph_source.points[src_pt_idx]
                mean_xyz = (orig_xyz + new_xyz) / 2
                points.SetPoint(src_pt_idx, mean_xyz)
        elif align_type == &#39;weighted&#39;:
            for src_pt_idx in range(self.graph_source.n_points):
                orig_xyz = self.weighted_avg_transformed_points[src_pt_idx]
                new_xyz = self.graph_source.points[src_pt_idx]
                mean_xyz = (orig_xyz + new_xyz) / 2
                points.SetPoint(src_pt_idx, mean_xyz)


    &#34;&#34;&#34;
    Spectral Weighting
    &#34;&#34;&#34;

    def calc_c_weighting_spectral(self):
        &#34;&#34;&#34;
        calculate spectral weighting coefficient. If 10 spectral coorindates (per point), would calculate
        10 weighting coefficients to weight importance of these coordinates.

        c^(u) = exp( -(Q^u * lambda^u)^2 / 2sigma^2)

        lambda^u = uth eigenvalue and represents smoothness of eigenvector (spectral coordinates)
        Q^u = confidence in re-ordered postion of uth set of eigenvactors, eigenvalues - from the dissimilarity
            matrix Q.
        sigma = mean {Q^u * lambda^u} subscript (u=1...m)


        Because this step is finally done with re-ordering etc. We should probably use only the n spectral coords that
        we intend to use for the analysis.



        :return:
        &#34;&#34;&#34;

        # highest eigenvalue weight from the two meshes (for a given pair).
        self.spectral_weights = self.Q[:self.n_spectral_features] \
                                * np.max((self.graph_source.eig_vals[:self.n_spectral_features],
                                      self.graph_target.eig_vals[:self.n_spectral_features]),
                                      axis=0)
        # Q is a weighting factor to get the mean weight (across the different spectral coordinates).
        sigma = np.mean(self.spectral_weights)
        self.spectral_weights = np.exp(-(self.spectral_weights ** 2) / (2 * sigma ** 2))

    def calc_weighted_spectral_coords(self):
        self.calc_c_weighting_spectral()
        self.source_spectral_coords = self.graph_source.eig_vecs[:, :self.n_spectral_features] \
                                      * self.spectral_weights[None, :]
        self.target_spectral_coords = self.graph_target.eig_vecs[:, :self.n_spectral_features] \
                                      * self.spectral_weights[None, :]

    def calc_spectral_coords(self):
        if self.get_weighted_spectral_coords is True:
            self.calc_weighted_spectral_coords()
        elif self.get_weighted_spectral_coords is False:
            self.source_spectral_coords = self.graph_source.eig_vecs[:, :self.n_spectral_features]
            self.target_spectral_coords = self.graph_target.eig_vecs[:, :self.n_spectral_features]

    &#34;&#34;&#34;
    Align Maps
    &#34;&#34;&#34;

    def align_maps(self):
        eig_map_sorter = eigsort(graph_target=self.graph_target,
                                 graph_source=self.graph_source,
                                 n_features=self.n_total_spectral_features,
                                 target_as_reference=self.target_eigenmap_as_reference)
        self.Q = eig_map_sorter.sort_eigenmaps()
        self.calc_spectral_coords()

        if (self.graph_source.n_extra_features &gt; 0) &amp; (self.use_features_as_coords is True):
            self.append_features_to_spectral_coords()

        if self.include_points_as_features is True:
            self.append_pts_to_spectral_coords()

        self.source_spectral_coords_b4_reg = np.copy(self.source_spectral_coords)

        print(&#39;Number of features (including spectral) &#39;
              &#39;used for registartion: {}&#39;.format(self.target_spectral_coords.shape[1]))

        if self.rigid_before_non_rigid_reg is True:
            print_header(&#39;Rigid Registration Beginning!&#39;)
            self.register_target_to_source(reg_type=&#39;affine&#39;)
            self.source_spectral_coords_after_rigid = np.copy(self.source_spectral_coords)

        print_header(&#39;Non-Rigid (Deformable) Registration Beginning&#39;)
        self.register_target_to_source(&#39;deformable&#39;)

        self.get_initial_correspondences()
        print(&#39;Number of unique correspondences: {}&#39;.format(len(np.unique(self.corresponding_target_idx_for_each_source_pt))
                                                            ))
        if self.smooth_correspondences is True:
            self.get_smoothed_correspondences()
            print(&#39;Number of unique correspondences after smoothing: {}&#39;.format(
                len(np.unique(self.corresponding_target_idx_for_each_source_pt))
                ))

        if self.return_average_final_points is True:
            self.get_weighted_final_node_locations()
        if self.return_nearest_final_points is True:
            self.get_nearest_neighbour_final_node_locations()

        if self.return_transformed_mesh is True:
            if self.return_average_final_points is True:
                self.get_source_mesh_transformed_weighted_avg()
            if self.return_nearest_final_points is True:
                self.get_source_mesh_transformed_nearest_neighbour()

        # return self.corresponding_target_idx_for_each_source_pt

    &#34;&#34;&#34;
    Change mesh scalar values (for visualizations). 
    &#34;&#34;&#34;

    def set_transformed_source_scalars_to_corresp_target_idx(self):
        if self.weighted_avg_transformed_mesh is not None:
            self.weighted_avg_transformed_mesh.GetPointData().SetScalars(
            numpy_to_vtk(self.corresponding_target_idx_for_each_source_pt))
        if self.nearest_neighbour_transformed_mesh is not None:
            self.nearest_neighbour_transformed_mesh.GetPointData().SetScalars(
            numpy_to_vtk(self.corresponding_target_idx_for_each_source_pt))

    def set_source_scalars_to_corresp_target_idx(self):
        self.graph_source.vtk_mesh.GetPointData().SetScalars(
            numpy_to_vtk(self.corresponding_target_idx_for_each_source_pt))

    def set_target_scalars_to_corresp_target_idx(self):
        self.graph_target.vtk_mesh.GetPointData().SetScalars(
            numpy_to_vtk(np.arange(self.graph_target.n_points)))

    def set_all_mesh_scalars_to_corresp_target_idx(self):
        self.set_target_scalars_to_corresp_target_idx()
        self.set_source_scalars_to_corresp_target_idx()
        self.set_transformed_source_scalars_to_corresp_target_idx()

    &#34;&#34;&#34;
    Probing &amp; View Results
    &#34;&#34;&#34;
    def get_source_mesh_transformed_weighted_avg(self):
        &#34;&#34;&#34;
        Create new mesh same as source mesh. Get source points. Move source points to transformed location(s) on
        target mesh using weighted average locations.
        :return:
        &#34;&#34;&#34;
        self.weighted_avg_transformed_mesh = vtk_deep_copy(self.graph_source.vtk_mesh)
        points = self.weighted_avg_transformed_mesh.GetPoints()
        for src_pt_idx in range(self.graph_source.n_points):
            points.SetPoint(src_pt_idx, self.weighted_avg_transformed_points[src_pt_idx])

    def get_source_mesh_transformed_nearest_neighbour(self):
        &#34;&#34;&#34;
        Create new mesh same as source mesh. Get source points. Move source points to transformed location(s) on
        target mesh using nearest neighbour locations.
        :return:
        &#34;&#34;&#34;
        self.nearest_neighbour_transformed_mesh = vtk_deep_copy(self.graph_source.vtk_mesh)
        points = self.nearest_neighbour_transformed_mesh.GetPoints()
        for src_pt_idx in range(self.graph_source.n_points):
            points.SetPoint(src_pt_idx, self.nearest_neighbor_transformed_points[src_pt_idx])

    # def get_source_mesh_transformed(self):
    #     &#34;&#34;&#34;
    #     Create new mesh same as source mesh. Get source points. Move source points to transformed location(s) on
    #     target mesh.
    #     :return:
    #     &#34;&#34;&#34;
    #     self.source_vtk_mesh_transformed = vtk_deep_copy(self.graph_source.vtk_mesh)
    #     points = self.source_vtk_mesh_transformed.GetPoints()
    #
    #     points = self.source_vtk_mesh_transformed.GetPoints()
    #     if self.diffuse_final_points is False:
    #         for src_pt_idx in range(self.graph_source.n_points):
    #             trget_pt_idx = self.corresponding_target_idx_for_each_source_pt[src_pt_idx]
    #             trget_pt_xyz = self.graph_target.vtk_mesh.GetPoint(trget_pt_idx)
    #             points.SetPoint(src_pt_idx, trget_pt_xyz)
    #     elif self.diffuse_final_points is True:
    #         for src_pt_idx in range(self.graph_source.n_points):
    #             points.SetPoint(src_pt_idx, self.weighted_avg_transformed_points[src_pt_idx])


    def view_aligned_spectral_coords(self, starting_spectral_coord=0,
                                     point_set_representations=[&#39;spheres&#39;],
                                     point_set_colors=None,
                                     include_target_coordinates=True,
                                     include_non_rigid_aligned=True,
                                     include_rigid_aligned=False,
                                     include_unaligned=False,
                                     upscale_factor=10.
                                     ):

        point_sets = []

        if include_target_coordinates is True:
            point_sets.append(upscale_factor
                              * np.ascontiguousarray(self.target_spectral_coords[:, starting_spectral_coord:starting_spectral_coord + 3]))

        if include_unaligned is True:
            point_sets.append(upscale_factor
                              * np.ascontiguousarray(self.source_spectral_coords_b4_reg[:, starting_spectral_coord:starting_spectral_coord + 3]))

        if include_rigid_aligned is True:
            point_sets.append(upscale_factor
                              * np.ascontiguousarray(self.source_spectral_coords_after_rigid[:, starting_spectral_coord:starting_spectral_coord + 3]))

        if include_non_rigid_aligned is True:
            point_sets.append(upscale_factor
                              * np.ascontiguousarray(self.source_spectral_coords[:, starting_spectral_coord:starting_spectral_coord+3]))

        # Make all the same shape, if only one specified and more than one point et included.
        if (len(point_set_representations) == 1) &amp; (len(point_sets) &gt; 1):
            point_set_representations = point_set_representations * len(point_sets)

        # Colours points sets sequentially using matplotlib V2 colours:
        if point_set_colors is None:
            point_set_colors = [colors.to_rgb(&#39;C{}&#39;.format(x)) for x in range(len(point_sets))]
        plotter = Viewer(point_sets=point_sets,
                         point_set_representations=point_set_representations,
                         point_set_colors=point_set_colors
                         )

        return plotter

    def view_meshes_colored_by_spectral_correspondences(self,
                                                        x_translation=100,
                                                        y_translation=0,
                                                        z_translation=0,
                                                        shadow=True):
        target_mesh = vtk_deep_copy(self.graph_target.vtk_mesh)
        target_mesh.GetPointData().SetScalars(numpy_to_vtk(np.arange(self.graph_target.n_points)))

        source_mesh = vtk_deep_copy(self.graph_source.vtk_mesh)
        source_mesh.GetPointData().SetScalars(numpy_to_vtk(self.corresponding_target_idx_for_each_source_pt))

        target_transform = vtk.vtkTransform()
        target_transform.Translate(x_translation, y_translation, z_translation)
        target_mesh = apply_transform(target_mesh, target_transform)

        plotter = Viewer(geometries=[source_mesh, target_mesh], shadow=shadow)
        return plotter

    def view_aligned_smoothed_spectral_coords(self):
        plotter = Viewer(point_sets=[self.smoothed_target_coords, self.source_projected_on_target],
                         point_set_colors=[colors.to_rgb(&#39;C0&#39;), colors.to_rgb(&#39;C1&#39;)])
        return plotter

    def view_meshes(self, include_target=True,
                    include_source=True,
                    include_transformed_target=False,
                    include_average=False,
                    shadow=True
                    ):
        geometries = []
        if include_target is True:
            geometries.append(self.graph_target.vtk_mesh)
        if include_source is True:
            geometries.append(self.graph_source.vtk_mesh)
        if include_transformed_target is True:
            if self.weighted_avg_transformed_mesh is not None:
                geometries.append(self.weighted_avg_transformed_mesh)
            elif self.nearest_neighbour_transformed_mesh is not None:
                geometries.append(self.nearest_neighbour_transformed_mesh)
            elif self.weighted_avg_transformed_points is not None:
                self.get_weighted_final_node_locations()
                self.get_source_mesh_transformed_weighted_avg()
                geometries.append(self.weighted_avg_transformed_mesh)
            elif self.nearest_neighbor_transformed_points is not None:
                self.get_nearest_neighbour_final_node_locations()
                self.get_source_mesh_transformed_nearest_neighbour()
                geometries.append(self.nearest_neighbour_transformed_mesh)
            else:
                raise Exception(&#39;No corresponding points or meshes calculated. Try running: \n&#39;
                                &#39;reg.get_weighted_final_node_locations()\n&#39;
                                &#39;reg.get_nearest_neighbour_final_node_locations()\n&#39;
                                &#39;or try re-running with the flags: \n&#39;
                                &#39;return_average_final_points=True &amp; return_transformed_mesh=True&#39;)
        if include_average is True:
            if self.average_mesh is None:
                if self.weighted_avg_transformed_points is not None:
                    self.get_average_shape()
                elif self.nearest_neighbor_transformed_points is not None:
                    self.get_average_shape(align_type=&#39;nearest&#39;)
                else:
                    raise Exception(&#34;No xyz correspondences calculated can&#39;t get average! Try:\n&#34;
                                    &#34;`reg.get_weighted_final_node_locations` or `reg.get_nearest_neighbour_final_node_locations`&#34;)
            geometries.append(self.average_mesh)

        plotter = Viewer(geometries=geometries, shadow=shadow)
        return plotter</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="pyfocusr.focusr.Focusr.align_maps"><code class="name flex">
<span>def <span class="ident">align_maps</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def align_maps(self):
    eig_map_sorter = eigsort(graph_target=self.graph_target,
                             graph_source=self.graph_source,
                             n_features=self.n_total_spectral_features,
                             target_as_reference=self.target_eigenmap_as_reference)
    self.Q = eig_map_sorter.sort_eigenmaps()
    self.calc_spectral_coords()

    if (self.graph_source.n_extra_features &gt; 0) &amp; (self.use_features_as_coords is True):
        self.append_features_to_spectral_coords()

    if self.include_points_as_features is True:
        self.append_pts_to_spectral_coords()

    self.source_spectral_coords_b4_reg = np.copy(self.source_spectral_coords)

    print(&#39;Number of features (including spectral) &#39;
          &#39;used for registartion: {}&#39;.format(self.target_spectral_coords.shape[1]))

    if self.rigid_before_non_rigid_reg is True:
        print_header(&#39;Rigid Registration Beginning!&#39;)
        self.register_target_to_source(reg_type=&#39;affine&#39;)
        self.source_spectral_coords_after_rigid = np.copy(self.source_spectral_coords)

    print_header(&#39;Non-Rigid (Deformable) Registration Beginning&#39;)
    self.register_target_to_source(&#39;deformable&#39;)

    self.get_initial_correspondences()
    print(&#39;Number of unique correspondences: {}&#39;.format(len(np.unique(self.corresponding_target_idx_for_each_source_pt))
                                                        ))
    if self.smooth_correspondences is True:
        self.get_smoothed_correspondences()
        print(&#39;Number of unique correspondences after smoothing: {}&#39;.format(
            len(np.unique(self.corresponding_target_idx_for_each_source_pt))
            ))

    if self.return_average_final_points is True:
        self.get_weighted_final_node_locations()
    if self.return_nearest_final_points is True:
        self.get_nearest_neighbour_final_node_locations()

    if self.return_transformed_mesh is True:
        if self.return_average_final_points is True:
            self.get_source_mesh_transformed_weighted_avg()
        if self.return_nearest_final_points is True:
            self.get_source_mesh_transformed_nearest_neighbour()

    # return self.corresponding_target_idx_for_each_source_pt</code></pre>
</details>
</dd>
<dt id="pyfocusr.focusr.Focusr.append_features_to_spectral_coords"><code class="name flex">
<span>def <span class="ident">append_features_to_spectral_coords</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def append_features_to_spectral_coords(self):
    print(&#39;Appending Extra Features to Spectral Coords&#39;)
    if self.graph_source.n_extra_features != self.graph_target.n_extra_features:
        raise Exception(&#39;Number of extra features between&#39;
                        &#39; target ({}) and source ({}) dont match!&#39;.format(self.graph_target.n_extra_features,
                                                                          self.graph_source.n_extra_features))

    self.source_extra_features = np.zeros((self.graph_source.n_points, self.graph_source.n_extra_features))
    self.target_extra_features = np.zeros((self.graph_target.n_points, self.graph_target.n_extra_features))

    for feature_idx in range(self.graph_source.n_extra_features):
        self.source_extra_features[:, feature_idx] = self.graph_source.mean_filter_graph(
            self.graph_source.node_features[feature_idx], iterations=self.feature_smoothing_iterations)
        self.source_extra_features[:, feature_idx] = self.source_extra_features[:, feature_idx] \
                                                     - np.min(self.source_extra_features[:, feature_idx])
        self.source_extra_features[:, feature_idx] = self.source_extra_features[:, feature_idx] \
                                                     / np.max(self.source_extra_features[:, feature_idx])
        self.source_extra_features[:, feature_idx] = np.ptp(self.source_spectral_coords) * self.source_extra_features[:, feature_idx]

        self.target_extra_features[:, feature_idx] = self.graph_target.mean_filter_graph(
            self.graph_target.node_features[feature_idx], iterations=self.feature_smoothing_iterations)
        self.target_extra_features[:, feature_idx] = self.target_extra_features[:, feature_idx] \
                                                     - np.min(self.target_extra_features[:, feature_idx])
        self.target_extra_features[:, feature_idx] = self.target_extra_features[:, feature_idx] \
                                                     / np.max(self.target_extra_features[:, feature_idx])
        self.target_extra_features[:, feature_idx] = np.ptp(
            self.target_spectral_coords) * self.target_extra_features[:, feature_idx]

    self.source_spectral_coords = np.concatenate((self.source_spectral_coords,
                                                  self.source_extra_features), axis=1)
    self.target_spectral_coords = np.concatenate((self.target_spectral_coords,
                                                  self.target_extra_features), axis=1)</code></pre>
</details>
</dd>
<dt id="pyfocusr.focusr.Focusr.append_pts_to_spectral_coords"><code class="name flex">
<span>def <span class="ident">append_pts_to_spectral_coords</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def append_pts_to_spectral_coords(self):
    if self.norm_physical_and_spectral is True:
        self.source_spectral_coords = np.concatenate((self.source_spectral_coords,
                                                      self.graph_source.normed_points), axis=1)
        self.target_spectral_coords = np.concatenate((self.target_spectral_coords,
                                                      self.graph_target.normed_points), axis=1)
    elif self.norm_physical_and_spectral is False:
        # If we dont scale everything down to be 0-1, then assume that we scale everything up to be the same
        # dimensions/range as the original image.
        self.source_spectral_coords = np.concatenate((self.source_spectral_coords
                                                      * self.graph_source.mean_pts_scale_range,
                                                      self.graph_source.points), axis=1)
        self.target_spectral_coords = np.concatenate((self.target_spectral_coords
                                                      * self.graph_target.mean_pts_scale_range,
                                                      self.graph_target.points), axis=1)</code></pre>
</details>
</dd>
<dt id="pyfocusr.focusr.Focusr.calc_c_weighting_spectral"><code class="name flex">
<span>def <span class="ident">calc_c_weighting_spectral</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>calculate spectral weighting coefficient. If 10 spectral coorindates (per point), would calculate
10 weighting coefficients to weight importance of these coordinates.</p>
<p>c^(u) = exp( -(Q^u * lambda^u)^2 / 2sigma^2)</p>
<p>lambda^u = uth eigenvalue and represents smoothness of eigenvector (spectral coordinates)
Q^u = confidence in re-ordered postion of uth set of eigenvactors, eigenvalues - from the dissimilarity
matrix Q.
sigma = mean {Q^u * lambda^u} subscript (u=1&hellip;m)</p>
<p>Because this step is finally done with re-ordering etc. We should probably use only the n spectral coords that
we intend to use for the analysis.</p>
<p>:return:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calc_c_weighting_spectral(self):
    &#34;&#34;&#34;
    calculate spectral weighting coefficient. If 10 spectral coorindates (per point), would calculate
    10 weighting coefficients to weight importance of these coordinates.

    c^(u) = exp( -(Q^u * lambda^u)^2 / 2sigma^2)

    lambda^u = uth eigenvalue and represents smoothness of eigenvector (spectral coordinates)
    Q^u = confidence in re-ordered postion of uth set of eigenvactors, eigenvalues - from the dissimilarity
        matrix Q.
    sigma = mean {Q^u * lambda^u} subscript (u=1...m)


    Because this step is finally done with re-ordering etc. We should probably use only the n spectral coords that
    we intend to use for the analysis.



    :return:
    &#34;&#34;&#34;

    # highest eigenvalue weight from the two meshes (for a given pair).
    self.spectral_weights = self.Q[:self.n_spectral_features] \
                            * np.max((self.graph_source.eig_vals[:self.n_spectral_features],
                                  self.graph_target.eig_vals[:self.n_spectral_features]),
                                  axis=0)
    # Q is a weighting factor to get the mean weight (across the different spectral coordinates).
    sigma = np.mean(self.spectral_weights)
    self.spectral_weights = np.exp(-(self.spectral_weights ** 2) / (2 * sigma ** 2))</code></pre>
</details>
</dd>
<dt id="pyfocusr.focusr.Focusr.calc_spectral_coords"><code class="name flex">
<span>def <span class="ident">calc_spectral_coords</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calc_spectral_coords(self):
    if self.get_weighted_spectral_coords is True:
        self.calc_weighted_spectral_coords()
    elif self.get_weighted_spectral_coords is False:
        self.source_spectral_coords = self.graph_source.eig_vecs[:, :self.n_spectral_features]
        self.target_spectral_coords = self.graph_target.eig_vecs[:, :self.n_spectral_features]</code></pre>
</details>
</dd>
<dt id="pyfocusr.focusr.Focusr.calc_weighted_spectral_coords"><code class="name flex">
<span>def <span class="ident">calc_weighted_spectral_coords</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calc_weighted_spectral_coords(self):
    self.calc_c_weighting_spectral()
    self.source_spectral_coords = self.graph_source.eig_vecs[:, :self.n_spectral_features] \
                                  * self.spectral_weights[None, :]
    self.target_spectral_coords = self.graph_target.eig_vecs[:, :self.n_spectral_features] \
                                  * self.spectral_weights[None, :]</code></pre>
</details>
</dd>
<dt id="pyfocusr.focusr.Focusr.get_average_shape"><code class="name flex">
<span>def <span class="ident">get_average_shape</span></span>(<span>self, align_type='weighted')</span>
</code></dt>
<dd>
<div class="desc"><p>Get new mesh average of the transformed source &amp; target.
:return:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_average_shape(self, align_type=&#39;weighted&#39;):
    &#34;&#34;&#34;
    Get new mesh average of the transformed source &amp; target.
    :return:
    &#34;&#34;&#34;
    self.average_mesh = vtk_deep_copy(self.graph_source.vtk_mesh)

    points = self.average_mesh.GetPoints()
    if align_type == &#39;nearest&#39;:
        for src_pt_idx in range(self.graph_source.n_points):
            trget_pt_idx = self.corresponding_target_idx_for_each_source_pt[src_pt_idx]
            new_xyz = self.graph_target.vtk_mesh.GetPoint(trget_pt_idx)
            orig_xyz = self.graph_source.points[src_pt_idx]
            mean_xyz = (orig_xyz + new_xyz) / 2
            points.SetPoint(src_pt_idx, mean_xyz)
    elif align_type == &#39;weighted&#39;:
        for src_pt_idx in range(self.graph_source.n_points):
            orig_xyz = self.weighted_avg_transformed_points[src_pt_idx]
            new_xyz = self.graph_source.points[src_pt_idx]
            mean_xyz = (orig_xyz + new_xyz) / 2
            points.SetPoint(src_pt_idx, mean_xyz)</code></pre>
</details>
</dd>
<dt id="pyfocusr.focusr.Focusr.get_hungarian_correspondence"><code class="name flex">
<span>def <span class="ident">get_hungarian_correspondence</span></span>(<span>self, target_pts, spectral_pts)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_hungarian_correspondence(self, target_pts, spectral_pts):
    tic = time.time()
    distances = cdist(spectral_pts, target_pts)
    toc = time.time()
    print(&#39;time to get cdist: {}&#39;.format(toc - tic))
    tic = time.time()
    source_idx, target_idx = linear_sum_assignment(distances)
    toc = time.time()
    print(&#39;time to linear sum assignment: {}&#39;.format(toc - tic))
    self.corresponding_target_idx_for_each_source_pt = target_idx</code></pre>
</details>
</dd>
<dt id="pyfocusr.focusr.Focusr.get_initial_correspondences"><code class="name flex">
<span>def <span class="ident">get_initial_correspondences</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Find target idx that is closest to each source point.
The correspondences indicate where (on the target mesh) each source point should move to.
:return:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_initial_correspondences(self):
    &#34;&#34;&#34;
    Find target idx that is closest to each source point.
    The correspondences indicate where (on the target mesh) each source point should move to.
    :return:
    &#34;&#34;&#34;
    if self.initial_correspondence_type == &#39;kd&#39;:
        self.get_kd_correspondence(self.target_spectral_coords, self.source_spectral_coords)
    elif self.initial_correspondence_type == &#39;hungarian&#39;:
        self.get_hungarian_correspondence(self.target_spectral_coords, self.source_spectral_coords)</code></pre>
</details>
</dd>
<dt id="pyfocusr.focusr.Focusr.get_kd_correspondence"><code class="name flex">
<span>def <span class="ident">get_kd_correspondence</span></span>(<span>self, target_pts, spectral_pts)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_kd_correspondence(self, target_pts, spectral_pts):
    tree = KDTree(target_pts)
    _, self.corresponding_target_idx_for_each_source_pt = tree.query(spectral_pts)</code></pre>
</details>
</dd>
<dt id="pyfocusr.focusr.Focusr.get_nearest_neighbour_final_node_locations"><code class="name flex">
<span>def <span class="ident">get_nearest_neighbour_final_node_locations</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_nearest_neighbour_final_node_locations(self):
    self.nearest_neighbor_transformed_points = self.graph_target.points[self.corresponding_target_idx_for_each_source_pt, :]</code></pre>
</details>
</dd>
<dt id="pyfocusr.focusr.Focusr.get_smoothed_correspondences"><code class="name flex">
<span>def <span class="ident">get_smoothed_correspondences</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_smoothed_correspondences(self):
    # Smooth the XYZ vertices using adjacency matrix for target
    # This will filter the target points using a low-pass filter
    self.smoothed_target_coords = self.graph_target.mean_filter_graph(self.graph_target.points,
                                                                      iterations=self.graph_smoothing_iterations)
    # Next, we take each of these smoothed points (particularly arranged based on which ones best align with
    # the spectral coordinates of the target mesh) and we smooth these vertices/values using the adjacency/degree
    # matrix of the source mesh. I.e. the target mesh coordinates are smoothed on the surface of the source mesh.
    if ((self.smoothed_target_coords.shape[0] != self.graph_source.n_points)
            &amp; (self.initial_correspondence_type == &#39;hungarian&#39;)):
        raise Exception(&#34;If number vertices between source &amp; target don&#39;t match, initial_correspondence_type must\n&#34;
                        &#34;be &#39;kd&#39; and not &#39;hungarian&#39;. Current type is: {}&#34;.format(self.initial_correspondence_type))
    self.source_projected_on_target = self.graph_source.mean_filter_graph(self.smoothed_target_coords[self.corresponding_target_idx_for_each_source_pt, :],
                                                                          iterations=self.projection_smooth_iterations)

    if self.final_correspondence_type == &#39;kd&#39;:
        self.get_kd_correspondence(self.smoothed_target_coords, self.source_projected_on_target)
    elif self.final_correspondence_type == &#39;hungarian&#39;:
        self.get_hungarian_correspondence(self.smoothed_target_coords, self.source_projected_on_target)

    # This now matches/makes correspondences. Can use this correspondence.
    # Or can associate with points in between these points...</code></pre>
</details>
</dd>
<dt id="pyfocusr.focusr.Focusr.get_source_mesh_transformed_nearest_neighbour"><code class="name flex">
<span>def <span class="ident">get_source_mesh_transformed_nearest_neighbour</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Create new mesh same as source mesh. Get source points. Move source points to transformed location(s) on
target mesh using nearest neighbour locations.
:return:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_source_mesh_transformed_nearest_neighbour(self):
    &#34;&#34;&#34;
    Create new mesh same as source mesh. Get source points. Move source points to transformed location(s) on
    target mesh using nearest neighbour locations.
    :return:
    &#34;&#34;&#34;
    self.nearest_neighbour_transformed_mesh = vtk_deep_copy(self.graph_source.vtk_mesh)
    points = self.nearest_neighbour_transformed_mesh.GetPoints()
    for src_pt_idx in range(self.graph_source.n_points):
        points.SetPoint(src_pt_idx, self.nearest_neighbor_transformed_points[src_pt_idx])</code></pre>
</details>
</dd>
<dt id="pyfocusr.focusr.Focusr.get_source_mesh_transformed_weighted_avg"><code class="name flex">
<span>def <span class="ident">get_source_mesh_transformed_weighted_avg</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Create new mesh same as source mesh. Get source points. Move source points to transformed location(s) on
target mesh using weighted average locations.
:return:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_source_mesh_transformed_weighted_avg(self):
    &#34;&#34;&#34;
    Create new mesh same as source mesh. Get source points. Move source points to transformed location(s) on
    target mesh using weighted average locations.
    :return:
    &#34;&#34;&#34;
    self.weighted_avg_transformed_mesh = vtk_deep_copy(self.graph_source.vtk_mesh)
    points = self.weighted_avg_transformed_mesh.GetPoints()
    for src_pt_idx in range(self.graph_source.n_points):
        points.SetPoint(src_pt_idx, self.weighted_avg_transformed_points[src_pt_idx])</code></pre>
</details>
</dd>
<dt id="pyfocusr.focusr.Focusr.get_weighted_final_node_locations"><code class="name flex">
<span>def <span class="ident">get_weighted_final_node_locations</span></span>(<span>self, n_closest_pts=3)</span>
</code></dt>
<dd>
<div class="desc"><p>Disperse points (from source) over the target mesh surface - distribute them instead of just finding the
closest point.
:return:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_weighted_final_node_locations(self, n_closest_pts=3):
    &#34;&#34;&#34;
    Disperse points (from source) over the target mesh surface - distribute them instead of just finding the
    closest point.
    :return:
    &#34;&#34;&#34;
    self.weighted_avg_transformed_points = np.zeros_like(self.graph_source.points)

    tree = KDTree(self.smoothed_target_coords)
    for pt_idx in range(self.graph_source.n_points):
        closest_pt_distances, closest_pt_idxs = tree.query(self.source_projected_on_target[pt_idx, :],
                                                           k=n_closest_pts)

        if 0 in closest_pt_distances:
            idx_coincident = np.where(closest_pt_distances == 0)[0][0]
            self.weighted_avg_transformed_points[pt_idx, :] = self.graph_target.points[closest_pt_idxs[idx_coincident]]
        else:
            weighting = 1 / closest_pt_distances[:, None]

            avg_location = np.sum(self.graph_target.points[closest_pt_idxs, :] * weighting, axis=0) / (sum(weighting))
            self.weighted_avg_transformed_points[pt_idx, :] = avg_location</code></pre>
</details>
</dd>
<dt id="pyfocusr.focusr.Focusr.register_target_to_source"><code class="name flex">
<span>def <span class="ident">register_target_to_source</span></span>(<span>self, reg_type='deformable')</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def register_target_to_source(self, reg_type=&#39;deformable&#39;):
    if reg_type == &#39;deformable&#39;:
        reg = cycpd.deformable_registration(**{
            &#39;X&#39;: self.source_spectral_coords[
                 self.graph_source.get_list_rand_idxs(self.n_coords_spectral_registration), :],
            &#39;Y&#39;: self.target_spectral_coords[
                 self.graph_target.get_list_rand_idxs(self.n_coords_spectral_registration), :],
            &#39;num_eig&#39;: self.non_rigid_n_eigens,
            &#39;max_iterations&#39;: self.non_rigid_max_iterations,
            &#39;tolerance&#39;: self.non_rigid_tolerance,
            &#39;alpha&#39;: self.non_rigid_alpha,
            &#39;beta&#39;: self.non_rigid_beta
        }
                                                      )
        _, self.non_rigid_params = reg.register()
    elif reg_type == &#39;affine&#39;:
        # Using affine instead of truly rigid, because rigid doesnt accept &gt;3 dimensions at moment.
        reg = cycpd.affine_registration(**{
            &#39;X&#39;: self.source_spectral_coords[
                 self.graph_source.get_list_rand_idxs(self.n_coords_spectral_registration), :],
            &#39;Y&#39;: self.target_spectral_coords[
                 self.graph_target.get_list_rand_idxs(self.n_coords_spectral_registration), :],
            &#39;max_iterations&#39;: self.rigid_reg_max_iterations,
            &#39;tolerance&#39;: self.rigid_tolerance
        }
                                              )
        _, self.rigid_params = reg.register()

    # Apply transform to all points (ensures all points are transformed even if not all used for registration).
    self.target_spectral_coords = reg.transform_point_cloud(self.target_spectral_coords)</code></pre>
</details>
</dd>
<dt id="pyfocusr.focusr.Focusr.set_all_mesh_scalars_to_corresp_target_idx"><code class="name flex">
<span>def <span class="ident">set_all_mesh_scalars_to_corresp_target_idx</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_all_mesh_scalars_to_corresp_target_idx(self):
    self.set_target_scalars_to_corresp_target_idx()
    self.set_source_scalars_to_corresp_target_idx()
    self.set_transformed_source_scalars_to_corresp_target_idx()</code></pre>
</details>
</dd>
<dt id="pyfocusr.focusr.Focusr.set_source_scalars_to_corresp_target_idx"><code class="name flex">
<span>def <span class="ident">set_source_scalars_to_corresp_target_idx</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_source_scalars_to_corresp_target_idx(self):
    self.graph_source.vtk_mesh.GetPointData().SetScalars(
        numpy_to_vtk(self.corresponding_target_idx_for_each_source_pt))</code></pre>
</details>
</dd>
<dt id="pyfocusr.focusr.Focusr.set_target_scalars_to_corresp_target_idx"><code class="name flex">
<span>def <span class="ident">set_target_scalars_to_corresp_target_idx</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_target_scalars_to_corresp_target_idx(self):
    self.graph_target.vtk_mesh.GetPointData().SetScalars(
        numpy_to_vtk(np.arange(self.graph_target.n_points)))</code></pre>
</details>
</dd>
<dt id="pyfocusr.focusr.Focusr.set_transformed_source_scalars_to_corresp_target_idx"><code class="name flex">
<span>def <span class="ident">set_transformed_source_scalars_to_corresp_target_idx</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_transformed_source_scalars_to_corresp_target_idx(self):
    if self.weighted_avg_transformed_mesh is not None:
        self.weighted_avg_transformed_mesh.GetPointData().SetScalars(
        numpy_to_vtk(self.corresponding_target_idx_for_each_source_pt))
    if self.nearest_neighbour_transformed_mesh is not None:
        self.nearest_neighbour_transformed_mesh.GetPointData().SetScalars(
        numpy_to_vtk(self.corresponding_target_idx_for_each_source_pt))</code></pre>
</details>
</dd>
<dt id="pyfocusr.focusr.Focusr.view_aligned_smoothed_spectral_coords"><code class="name flex">
<span>def <span class="ident">view_aligned_smoothed_spectral_coords</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def view_aligned_smoothed_spectral_coords(self):
    plotter = Viewer(point_sets=[self.smoothed_target_coords, self.source_projected_on_target],
                     point_set_colors=[colors.to_rgb(&#39;C0&#39;), colors.to_rgb(&#39;C1&#39;)])
    return plotter</code></pre>
</details>
</dd>
<dt id="pyfocusr.focusr.Focusr.view_aligned_spectral_coords"><code class="name flex">
<span>def <span class="ident">view_aligned_spectral_coords</span></span>(<span>self, starting_spectral_coord=0, point_set_representations=['spheres'], point_set_colors=None, include_target_coordinates=True, include_non_rigid_aligned=True, include_rigid_aligned=False, include_unaligned=False, upscale_factor=10.0)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def view_aligned_spectral_coords(self, starting_spectral_coord=0,
                                 point_set_representations=[&#39;spheres&#39;],
                                 point_set_colors=None,
                                 include_target_coordinates=True,
                                 include_non_rigid_aligned=True,
                                 include_rigid_aligned=False,
                                 include_unaligned=False,
                                 upscale_factor=10.
                                 ):

    point_sets = []

    if include_target_coordinates is True:
        point_sets.append(upscale_factor
                          * np.ascontiguousarray(self.target_spectral_coords[:, starting_spectral_coord:starting_spectral_coord + 3]))

    if include_unaligned is True:
        point_sets.append(upscale_factor
                          * np.ascontiguousarray(self.source_spectral_coords_b4_reg[:, starting_spectral_coord:starting_spectral_coord + 3]))

    if include_rigid_aligned is True:
        point_sets.append(upscale_factor
                          * np.ascontiguousarray(self.source_spectral_coords_after_rigid[:, starting_spectral_coord:starting_spectral_coord + 3]))

    if include_non_rigid_aligned is True:
        point_sets.append(upscale_factor
                          * np.ascontiguousarray(self.source_spectral_coords[:, starting_spectral_coord:starting_spectral_coord+3]))

    # Make all the same shape, if only one specified and more than one point et included.
    if (len(point_set_representations) == 1) &amp; (len(point_sets) &gt; 1):
        point_set_representations = point_set_representations * len(point_sets)

    # Colours points sets sequentially using matplotlib V2 colours:
    if point_set_colors is None:
        point_set_colors = [colors.to_rgb(&#39;C{}&#39;.format(x)) for x in range(len(point_sets))]
    plotter = Viewer(point_sets=point_sets,
                     point_set_representations=point_set_representations,
                     point_set_colors=point_set_colors
                     )

    return plotter</code></pre>
</details>
</dd>
<dt id="pyfocusr.focusr.Focusr.view_meshes"><code class="name flex">
<span>def <span class="ident">view_meshes</span></span>(<span>self, include_target=True, include_source=True, include_transformed_target=False, include_average=False, shadow=True)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def view_meshes(self, include_target=True,
                include_source=True,
                include_transformed_target=False,
                include_average=False,
                shadow=True
                ):
    geometries = []
    if include_target is True:
        geometries.append(self.graph_target.vtk_mesh)
    if include_source is True:
        geometries.append(self.graph_source.vtk_mesh)
    if include_transformed_target is True:
        if self.weighted_avg_transformed_mesh is not None:
            geometries.append(self.weighted_avg_transformed_mesh)
        elif self.nearest_neighbour_transformed_mesh is not None:
            geometries.append(self.nearest_neighbour_transformed_mesh)
        elif self.weighted_avg_transformed_points is not None:
            self.get_weighted_final_node_locations()
            self.get_source_mesh_transformed_weighted_avg()
            geometries.append(self.weighted_avg_transformed_mesh)
        elif self.nearest_neighbor_transformed_points is not None:
            self.get_nearest_neighbour_final_node_locations()
            self.get_source_mesh_transformed_nearest_neighbour()
            geometries.append(self.nearest_neighbour_transformed_mesh)
        else:
            raise Exception(&#39;No corresponding points or meshes calculated. Try running: \n&#39;
                            &#39;reg.get_weighted_final_node_locations()\n&#39;
                            &#39;reg.get_nearest_neighbour_final_node_locations()\n&#39;
                            &#39;or try re-running with the flags: \n&#39;
                            &#39;return_average_final_points=True &amp; return_transformed_mesh=True&#39;)
    if include_average is True:
        if self.average_mesh is None:
            if self.weighted_avg_transformed_points is not None:
                self.get_average_shape()
            elif self.nearest_neighbor_transformed_points is not None:
                self.get_average_shape(align_type=&#39;nearest&#39;)
            else:
                raise Exception(&#34;No xyz correspondences calculated can&#39;t get average! Try:\n&#34;
                                &#34;`reg.get_weighted_final_node_locations` or `reg.get_nearest_neighbour_final_node_locations`&#34;)
        geometries.append(self.average_mesh)

    plotter = Viewer(geometries=geometries, shadow=shadow)
    return plotter</code></pre>
</details>
</dd>
<dt id="pyfocusr.focusr.Focusr.view_meshes_colored_by_spectral_correspondences"><code class="name flex">
<span>def <span class="ident">view_meshes_colored_by_spectral_correspondences</span></span>(<span>self, x_translation=100, y_translation=0, z_translation=0, shadow=True)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def view_meshes_colored_by_spectral_correspondences(self,
                                                    x_translation=100,
                                                    y_translation=0,
                                                    z_translation=0,
                                                    shadow=True):
    target_mesh = vtk_deep_copy(self.graph_target.vtk_mesh)
    target_mesh.GetPointData().SetScalars(numpy_to_vtk(np.arange(self.graph_target.n_points)))

    source_mesh = vtk_deep_copy(self.graph_source.vtk_mesh)
    source_mesh.GetPointData().SetScalars(numpy_to_vtk(self.corresponding_target_idx_for_each_source_pt))

    target_transform = vtk.vtkTransform()
    target_transform.Translate(x_translation, y_translation, z_translation)
    target_mesh = apply_transform(target_mesh, target_transform)

    plotter = Viewer(geometries=[source_mesh, target_mesh], shadow=shadow)
    return plotter</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="pyfocusr" href="index.html">pyfocusr</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="pyfocusr.focusr.Focusr" href="#pyfocusr.focusr.Focusr">Focusr</a></code></h4>
<ul class="">
<li><code><a title="pyfocusr.focusr.Focusr.align_maps" href="#pyfocusr.focusr.Focusr.align_maps">align_maps</a></code></li>
<li><code><a title="pyfocusr.focusr.Focusr.append_features_to_spectral_coords" href="#pyfocusr.focusr.Focusr.append_features_to_spectral_coords">append_features_to_spectral_coords</a></code></li>
<li><code><a title="pyfocusr.focusr.Focusr.append_pts_to_spectral_coords" href="#pyfocusr.focusr.Focusr.append_pts_to_spectral_coords">append_pts_to_spectral_coords</a></code></li>
<li><code><a title="pyfocusr.focusr.Focusr.calc_c_weighting_spectral" href="#pyfocusr.focusr.Focusr.calc_c_weighting_spectral">calc_c_weighting_spectral</a></code></li>
<li><code><a title="pyfocusr.focusr.Focusr.calc_spectral_coords" href="#pyfocusr.focusr.Focusr.calc_spectral_coords">calc_spectral_coords</a></code></li>
<li><code><a title="pyfocusr.focusr.Focusr.calc_weighted_spectral_coords" href="#pyfocusr.focusr.Focusr.calc_weighted_spectral_coords">calc_weighted_spectral_coords</a></code></li>
<li><code><a title="pyfocusr.focusr.Focusr.get_average_shape" href="#pyfocusr.focusr.Focusr.get_average_shape">get_average_shape</a></code></li>
<li><code><a title="pyfocusr.focusr.Focusr.get_hungarian_correspondence" href="#pyfocusr.focusr.Focusr.get_hungarian_correspondence">get_hungarian_correspondence</a></code></li>
<li><code><a title="pyfocusr.focusr.Focusr.get_initial_correspondences" href="#pyfocusr.focusr.Focusr.get_initial_correspondences">get_initial_correspondences</a></code></li>
<li><code><a title="pyfocusr.focusr.Focusr.get_kd_correspondence" href="#pyfocusr.focusr.Focusr.get_kd_correspondence">get_kd_correspondence</a></code></li>
<li><code><a title="pyfocusr.focusr.Focusr.get_nearest_neighbour_final_node_locations" href="#pyfocusr.focusr.Focusr.get_nearest_neighbour_final_node_locations">get_nearest_neighbour_final_node_locations</a></code></li>
<li><code><a title="pyfocusr.focusr.Focusr.get_smoothed_correspondences" href="#pyfocusr.focusr.Focusr.get_smoothed_correspondences">get_smoothed_correspondences</a></code></li>
<li><code><a title="pyfocusr.focusr.Focusr.get_source_mesh_transformed_nearest_neighbour" href="#pyfocusr.focusr.Focusr.get_source_mesh_transformed_nearest_neighbour">get_source_mesh_transformed_nearest_neighbour</a></code></li>
<li><code><a title="pyfocusr.focusr.Focusr.get_source_mesh_transformed_weighted_avg" href="#pyfocusr.focusr.Focusr.get_source_mesh_transformed_weighted_avg">get_source_mesh_transformed_weighted_avg</a></code></li>
<li><code><a title="pyfocusr.focusr.Focusr.get_weighted_final_node_locations" href="#pyfocusr.focusr.Focusr.get_weighted_final_node_locations">get_weighted_final_node_locations</a></code></li>
<li><code><a title="pyfocusr.focusr.Focusr.register_target_to_source" href="#pyfocusr.focusr.Focusr.register_target_to_source">register_target_to_source</a></code></li>
<li><code><a title="pyfocusr.focusr.Focusr.set_all_mesh_scalars_to_corresp_target_idx" href="#pyfocusr.focusr.Focusr.set_all_mesh_scalars_to_corresp_target_idx">set_all_mesh_scalars_to_corresp_target_idx</a></code></li>
<li><code><a title="pyfocusr.focusr.Focusr.set_source_scalars_to_corresp_target_idx" href="#pyfocusr.focusr.Focusr.set_source_scalars_to_corresp_target_idx">set_source_scalars_to_corresp_target_idx</a></code></li>
<li><code><a title="pyfocusr.focusr.Focusr.set_target_scalars_to_corresp_target_idx" href="#pyfocusr.focusr.Focusr.set_target_scalars_to_corresp_target_idx">set_target_scalars_to_corresp_target_idx</a></code></li>
<li><code><a title="pyfocusr.focusr.Focusr.set_transformed_source_scalars_to_corresp_target_idx" href="#pyfocusr.focusr.Focusr.set_transformed_source_scalars_to_corresp_target_idx">set_transformed_source_scalars_to_corresp_target_idx</a></code></li>
<li><code><a title="pyfocusr.focusr.Focusr.view_aligned_smoothed_spectral_coords" href="#pyfocusr.focusr.Focusr.view_aligned_smoothed_spectral_coords">view_aligned_smoothed_spectral_coords</a></code></li>
<li><code><a title="pyfocusr.focusr.Focusr.view_aligned_spectral_coords" href="#pyfocusr.focusr.Focusr.view_aligned_spectral_coords">view_aligned_spectral_coords</a></code></li>
<li><code><a title="pyfocusr.focusr.Focusr.view_meshes" href="#pyfocusr.focusr.Focusr.view_meshes">view_meshes</a></code></li>
<li><code><a title="pyfocusr.focusr.Focusr.view_meshes_colored_by_spectral_correspondences" href="#pyfocusr.focusr.Focusr.view_meshes_colored_by_spectral_correspondences">view_meshes_colored_by_spectral_correspondences</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>